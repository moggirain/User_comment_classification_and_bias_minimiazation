{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T04:13:07.141077Z",
     "start_time": "2019-06-13T04:13:00.765769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:858: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/anaconda3/lib/python3.6/site-packages/ipywidgets/widgets/widget.py:281: DeprecationWarning:\n",
      "\n",
      "Widget registration using a string name has been deprecated. Widget registration now uses a plain `@register` decorator.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Credit to: https://www.kaggle.com/gpreda/jigsaw-eda\"\"\"\n",
    "\"\"\"Credit to  \"\"\"\n",
    "# garbaga collector interface\n",
    "import gc\n",
    "# Miscellaneous operating system interfaces\n",
    "import os\n",
    "# warning control\n",
    "import warnings\n",
    "# use standard operator as functions\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# progress bar \n",
    "from tqdm import tqdm_notebook\n",
    "# wordcloud \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# topic modeling library\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "# natural language toolkit \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem.porter import *\n",
    "# library for interactive topic model visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='moggirain', api_key='L7BSKLkbzBKYJwc8HEp6')\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "np.random.seed(2019)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T04:13:49.432282Z",
     "start_time": "2019-06-13T04:13:24.731121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 3.72 s, total: 23.5 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set the path \n",
    "PATH = \"./\"\n",
    "# load train dataset\n",
    "train = pd.read_csv(os.path.join(PATH,'train.csv'),index_col='id')\n",
    "# load test dataset \n",
    "test = pd.read_csv(os.path.join(PATH,'test.csv'),index_col= 'id')\n",
    "sub = pd.read_csv(os.path.join(PATH,'sample_submission.csv'),index_col = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "***Feature Explanation***\n",
    "\n",
    "- The text comments are stored in `train` and `test` in `comment_text` column.  \n",
    "\n",
    "***Target***\n",
    "\n",
    "- The target is represented by the fraction of scores. \n",
    "- Subset of target(toxic)attributes:\n",
    "\n",
    "`severe_toxicity`\n",
    "`obscene`\n",
    "`threat`\n",
    "`insult`\n",
    "`identity_attack`\n",
    "`sexual_explicit`\n",
    "\n",
    "***Train***\n",
    "\n",
    "- The 5 topic categories(5): \n",
    "* **race or ethnicity**: `asian`, `black`, `jewish`, `latino`, `other_race_or_ethnicity`, `white`  \n",
    "* **gender**: `female`, `male`, `transgender`, `other_gender`  \n",
    "* **sexual orientation**: `bisexual`, `heterosexual`, `homosexual_gay_or_lesbian`, `other_sexual_orientation`  \n",
    "* **religion**: `atheist`,`buddhist`,  `christian`, `hindu`, `muslim`, `other_religion`  \n",
    "* **disability**: `intellectual_or_learning_disability`, `other_disability`, `physical_disability`, `psychiatric_or_mental_illness` <br>\n",
    "<br>\n",
    "\n",
    "- The article/comment identification information  (4):\n",
    "* created_date* \n",
    "* publication_id***   \n",
    "* parent_id***  \n",
    "* article_id*** \n",
    "<br>\n",
    "\n",
    "- User feedback information associated with the comments are provided  (7):\n",
    "* rating  \n",
    "* funny  \n",
    "* wow  \n",
    "* sad  \n",
    "* likes  \n",
    "* disagree  \n",
    "* sexual_explicit  \n",
    "<br>\n",
    "- Annotations information (2):\n",
    "* identity_annotator_count  \n",
    "* toxicity_annotator_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:43.633780Z",
     "start_time": "2019-06-09T16:46:38.920717Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.sample(5))\n",
    "print(test.head())\n",
    "print(train.info())\n",
    "print(train.describe())\n",
    "print(test.describe())\n",
    "print(f\"Train and test shape:{train.shape} {test.shape}\")\n",
    "print(train.isnull().sum(), test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Feature\n",
    "- Target feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:44.092244Z",
     "start_time": "2019-06-09T16:46:43.636952Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "plt.title('Distribution of target in the train dataset')\n",
    "# kde = gaussian kernel density \n",
    "sns.distplot(train['target'],kde = True, hist = False, bins = 120, label = 'target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:44.149110Z",
     "start_time": "2019-06-09T16:46:44.095571Z"
    }
   },
   "outputs": [],
   "source": [
    "train['target'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "- Most target are distributed slightly around zero. \n",
    "- A second largest amount of target is around 0.2. \n",
    "- There are other peaks around 0.3, 0.4, 0.5, 0.6. (Think about how those score are generated)\n",
    "- From the following confirmation, 1254764 comments are with the target exactly zero. Most comments are not annotated as toxic. \n",
    "- High toxic comments are in a small number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-features of Target\n",
    "- Distribution of five sub-feature group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:44.156701Z",
     "start_time": "2019-06-09T16:46:44.151787Z"
    }
   },
   "outputs": [],
   "source": [
    "# build function to plot the features \n",
    "def plt_feature(features, title):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(title)\n",
    "    for f in features:\n",
    "        sns.distplot(train[f], kde = True, hist = False, bins = 120, label = f)\n",
    "    plt.xlabel ('')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:45.198556Z",
     "start_time": "2019-06-09T16:46:44.159737Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['severe_toxicity', 'obscene','identity_attack','insult','threat']\n",
    "plt_feature(features, 'Distribution of sub toxicity features in the train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:45.262330Z",
     "start_time": "2019-06-09T16:46:45.201272Z"
    }
   },
   "outputs": [],
   "source": [
    "train['severe_toxicity'].value_counts().sort_values(ascending = False)\n",
    "train['identity_attack'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "- All sub toxicity features are centered around several peaks. \n",
    "- Insult has the highest score and identity_attack is the second. \n",
    "- The several high peak of distribution for insult and identity attach and threat are similar, both around 0.1, 0.18, 0.2, 0.3,0.4, 0.5, 0.6. \n",
    "- The distribution of severe_toxity is centered around 0.1, with several high peaks between 0 to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive Topic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race & Ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:45.830304Z",
     "start_time": "2019-06-09T16:46:45.264886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Race and Ethnicity \n",
    "features = ['asian','black','jewish','latino','other_race_or_ethnicity','white']\n",
    "plt_feature(features,'Distribution of sensitive topic features in the train dataset ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:45.883309Z",
     "start_time": "2019-06-09T16:46:45.832519Z"
    }
   },
   "outputs": [],
   "source": [
    "train['white'].value_counts().sort_values(ascending = False)\n",
    "train['black'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "- Features are skewed toward 0.0-0.2 and 0.8-1.0. \n",
    "- Two most frequent feature is white and black and these two features had really high distribution around 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:46.345569Z",
     "start_time": "2019-06-09T16:46:45.886377Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['female','male','transgender','other_gender']\n",
    "plt_feature(features, \"Distribution of gender features in the train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "\n",
    "- Female and male are two most frequent group of concern. \n",
    "- Similarly, the distribution is with several peaks. \n",
    "- The high values are centered around 0.0-0.2 and 0.8-1.0. \n",
    "- Female has much more counts than male distributed in the highly toxic comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexual Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:46.784160Z",
     "start_time": "2019-06-09T16:46:46.349077Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['bisexual', 'heterosexual', 'homosexual_gay_or_lesbian', 'other_sexual_orientation']\n",
    "plt_feature(features, \"Distribution of sexual orientation features in the train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "\n",
    "- Homosexual_gay_or_lesbian is with much more frequency, especially centered around highly toxic comments (around 0.8-1.0). \n",
    "- Other_sexual_orientation is centered around 0.1, with high peaks around 0.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:47.325769Z",
     "start_time": "2019-06-09T16:46:46.787604Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['atheist','buddhist',  'christian', 'hindu', 'muslim', 'other_religion']\n",
    "plt_feature(features, \"Distribution of religion features values in the train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "\n",
    "- Christian and Muslim indicated higher frequency distribution. \n",
    "- Christians are distributed with relatively equal scores at each peak, but highly centered around 0.0-0.2 and 0.8-1.0, with much more counts around 1.0. \n",
    "- Muslim are with the similar trend as christian, but also highly centered around 0.0-0.2 and 0.8-1.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:47.868681Z",
     "start_time": "2019-06-09T16:46:47.328343Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['intellectual_or_learning_disability', 'other_disability', 'physical_disability', 'psychiatric_or_mental_illness']\n",
    "plt_feature(features, \"Distribution of disability features values in the train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "\n",
    "- Psychiatric_or_mental_illness has high frequency than other disabilities, with the peaks equally distributed around certain peaks.  \n",
    "- The high peaks of psychiatric_or_mental_illness are other around 0.18 and around 1.0. \n",
    "- The other_disability is around 0.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback Information\n",
    "- feedback values distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:47.879233Z",
     "start_time": "2019-06-09T16:46:47.871398Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_count(feature, title, size = 1):\n",
    "    f, ax = plt.subplots(1, 1, figsize = (4 * size, 4))\n",
    "    total = float(len(train))\n",
    "    g = sns.countplot(train[feature], order = train[feature].value_counts().index[:20],palette = 'Set1')\n",
    "    g.set_title(f\"count and percentage of {title}\")\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2.,\n",
    "               height + 3, \n",
    "               '{:1.2f}'.format(100*height/total),\n",
    "                ha = 'center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:48.444891Z",
     "start_time": "2019-06-09T16:46:47.882594Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot rating \n",
    "plot_count('rating','rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:48.846994Z",
     "start_time": "2019-06-09T16:46:48.447728Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_funny\n",
    "plot_count('funny','funny votes given', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:49.166076Z",
     "start_time": "2019-06-09T16:46:48.850293Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot wow\n",
    "plot_count('wow','wow votes given',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:49.530351Z",
     "start_time": "2019-06-09T16:46:49.169419Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_count('sad','sad votes given',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:49.906282Z",
     "start_time": "2019-06-09T16:46:49.533675Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_count('likes','likes given',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:50.294793Z",
     "start_time": "2019-06-09T16:46:49.909783Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_count('disagree','disagree given',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sexual_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:50.648873Z",
     "start_time": "2019-06-09T16:46:50.298803Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['sexual_explicit']\n",
    "plt_feature(features, 'Distribution of sexual explicit in the train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Text\n",
    "- wordcloud of top 50 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:50.659073Z",
     "start_time": "2019-06-09T16:46:50.652120Z"
    }
   },
   "outputs": [],
   "source": [
    "# set stopwords \n",
    "stopwords = set(STOPWORDS)\n",
    "# build wordcloud\n",
    "def word_cloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "    background_color = 'white',\n",
    "    stopwords = stopwords,\n",
    "    max_words = 100, \n",
    "    max_font_size = 40,\n",
    "    min_font_size = 6,\n",
    "    scale = 5, \n",
    "    random_state = 1).generate(str(data))\n",
    "    # plot the figure     \n",
    "    fig = plt.figure(1, figsize = (10,10))\n",
    "    plt.axis('off')\n",
    "    # set title\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize= 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comment_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:51.219596Z",
     "start_time": "2019-06-09T16:46:50.662238Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample 20000 comments sample and show top 100 words \n",
    "word_cloud(train['comment_text'].sample(50000), title = 'Prevalence among comments in the train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***explanation(from sample only)***\n",
    "- top 100 words: Maybe, vote, trump, need, sure, friend, mail, globe, don't\n",
    "- related to political,election,communication,affirmative words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:52.398790Z",
     "start_time": "2019-06-09T16:46:51.222444Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['insult']< 0.3]['comment_text'].sample(50000),\n",
    "           title = 'Prevalence insult comments in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:52.951541Z",
     "start_time": "2019-06-09T16:46:52.402287Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['insult']>0.7]['comment_text'].sample(20000),\n",
    "           title = 'Prevalence insult comments in the train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***explanation***\n",
    "- top words (<0.3): Muslims, Alaska, women, read, voted, wrong, like, law, news, time, said, ACA, left, leafs \n",
    "- top words (>0.7): Trump,Clinton,ideiot, mentally, stupid, clown, people, like, dumb, liar, think wrong \n",
    "- related to political,election, gender,intellectural ability, and news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:54.124080Z",
     "start_time": "2019-06-09T16:46:52.955200Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['threat'] < 0.3]['comment_text'],\n",
    "           title = 'Prevalence threat comments in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:54.630233Z",
     "start_time": "2019-06-09T16:46:54.127688Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['threat']>0.7]['comment_text'],\n",
    "           title = 'Prevalence threat comments in the train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:55.705821Z",
     "start_time": "2019-06-09T16:46:54.633562Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['obscene'] <0.3]['comment_text'],\n",
    "           title = 'Prevalence obscene comments in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:56.150994Z",
     "start_time": "2019-06-09T16:46:55.709034Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['obscene']>0.7]['comment_text'],\n",
    "           title = 'Prevalence obscene comments in the train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:57.076123Z",
     "start_time": "2019-06-09T16:46:56.155508Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['target']<0.3]['comment_text'],\n",
    "           title = 'Prevalence of words in target in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:57.546787Z",
     "start_time": "2019-06-09T16:46:57.079119Z"
    }
   },
   "outputs": [],
   "source": [
    "word_cloud(train.loc[train['target']>0.7]['comment_text'],\n",
    "           title = 'Prevalence of words in target in the train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## New Feature Creation[](http://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length \n",
    "col = \"comment_text\"\n",
    "train['lengths'] = train[col].apply(len)\n",
    "# check character distribution \n",
    "lengths = train.loc[train.lengths <1500]['lengths']\n",
    "sns.distplot(lengths, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the max length of the comment text \n",
    "train.lengths.max()\n",
    "train.lengths.mean()\n",
    "# np.quantitle(train_df.lengths,[0.25,0.75])\n",
    "train.lengths.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Explanation***\n",
    "> [](http://)\n",
    "- From the head and tail, we observe the bimodal distribution of character length in the data. Although the lengths seem to be heavily skewed to the lower lengths, we see another clear peak around the 1000 character mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of words\n",
    "train[\"num_words\"] = train[col].apply(lambda x: len(x.split()))\n",
    "# calculate the words length < 200\n",
    "words = train.loc[train.num_words < 200].num_words\n",
    "sns.distplot(words, color = 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.num_words.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****From the graph***, we observe a clear unimodal left-skewed distribution of the number of words in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Average Word Length\n",
    "- All characters / len(each word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['avg_word_len'] = train[col].apply(lambda x: 1.0*len(''.join(x.split()))/len(x.split()))\n",
    "avg_word_len = train.loc[train['avg_word_len']<8]['avg_word_len']\n",
    "sns.distplot(avg_word_len, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.avg_word_len.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Word Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['capitals'] = train['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "train['caps_vs_length'] = train.apply(lambda row: float(row['capitals'])/float(row['lengths']),axis=1)\n",
    "train['num_exclamation_marks'] = train['comment_text'].apply(lambda comment: comment.count('!'))\n",
    "train['num_question_marks'] = train['comment_text'].apply(lambda comment: comment.count('?'))\n",
    "train['num_punctuation'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "train['num_symbols'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n",
    "train['num_unique_words'] = train['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "train['words_vs_unique'] = train['num_unique_words'] / train['num_words']\n",
    "train['num_smilies'] = train['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between new features and sub-target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ('lengths', 'capitals', 'caps_vs_length', 'num_exclamation_marks','num_question_marks', 'num_punctuation', 'num_words', 'num_unique_words','words_vs_unique', 'num_smilies', 'num_symbols','avg_word_len')\n",
    "columns = ('target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'funny', 'wow', 'sad', 'likes', 'disagree', 'sexual_explicit','identity_annotator_count', 'toxicity_annotator_count')\n",
    "rows = [{c:train[f].corr(train[c]) for c in columns} for f in features]\n",
    "train_correlations = pd.DataFrame(rows, index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot the Heatmap***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(font_scale=1)\n",
    "ax = sns.heatmap(train_correlations, vmin=-0.1, vmax=0.1, center=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Explanation ***\n",
    "- number of `unique_words` and `likes` are highly correlated. \n",
    "- `words_vs_unique` and `funny` are highly correlated. \n",
    "- `funny` and ` num_words` and `num_unique_words` are highly negatively correlated. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = train.loc[:, ['target']+list(train)[slice(8,31)]].dropna()\n",
    "weighted_toxic = demographics.iloc[:, 1:].multiply(demographics.iloc[:, 0], axis=\"index\").sum()/demographics.iloc[:, 1:][demographics.iloc[:, 1:]>0].count()\n",
    "weighted_toxic = weighted_toxic.sort_values(ascending=False)\n",
    "# plot the features \n",
    "plt.figure(figsize=(30,20))\n",
    "sns.set(font_scale=3)\n",
    "ax = sns.barplot(x = weighted_toxic.values, y = weighted_toxic.index, alpha=0.8)\n",
    "plt.ylabel('Demographics')\n",
    "plt.xlabel('Weighted Toxic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted toxicity across features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identities = tuple(train.iloc[:, 8:31])\n",
    "rows = [{c:train[f].corr(train[c]) for c in columns} for f in identities]\n",
    "poptoxicity_correlations = pd.DataFrame(rows, index=identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptoxicity_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(font_scale=1)\n",
    "ax = sns.heatmap(poptoxicity_correlations, vmin=-0.1, vmax=0.1, center=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Explanation ***\n",
    "- `identity_attach` is highly correlated with black, homesexual, juewish, muslim. \n",
    "- `sexual_explicit` is highly correlated with female, homexual, male. \n",
    "- `target` is highly correlated with black, homesexual, muslim and white. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.created_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with date \n",
    "withdate = train.loc[:, ['created_date', 'target']+list(train)[slice(7,31)]].dropna()\n",
    "# calculate the race weighted ratio\n",
    "raceweighted = withdate.iloc[:, 2:]/withdate.iloc[:, 2:].sum()\n",
    "# calculate the ratio multiplied with target \n",
    "race_target_weighted = raceweighted.multiply(withdate.iloc[:, 1], axis=\"index\")\n",
    "# created a new column to change the datatype \n",
    "race_target_weighted['created_date'] = pd.to_datetime(withdate['created_date']).values.astype('datetime64[M]')\n",
    "# order by time stamp and sum the values and sort by months\n",
    "weighted_demo = race_target_weighted.groupby(['created_date']).sum().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race & Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_demo[['white', 'asian', 'black', 'jewish', 'latino', 'other_race_or_ethnicity']].iplot(title = 'Time Series Toxicity & Race', filename='Time Series Toxicity & Race' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_demo[['atheist', 'buddhist', 'christian', 'hindu', 'muslim', 'other_religion']].iplot(title = 'Time Series Toxicity & Religion', filename='Time Series Toxicity & Religion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexual Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_demo[['heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation']].iplot(title = 'Time Series Toxicity & Sexual Orientation', filename='Time Series Toxicity & Sexual Orientation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_demo[['male', 'female', 'transgender', 'other_gender']].iplot(title = 'Time Series Toxicity & Gender', filename='Time Series Toxicity & Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_demo[['physical_disability', 'intellectual_or_learning_disability', 'psychiatric_or_mental_illness', 'other_disability']].iplot(title = 'Time Series Toxicity & Disability', filename='Time Series Toxicity & Disability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldate_toxicity = train[train['target'] >= 0.5].loc[:, ['created_date', 'target', 'comment_text']].dropna()\n",
    "alldate_toxicity['created_date'] = pd.to_datetime(alldate_toxicity['created_date']).values.astype('datetime64[M]')\n",
    "jan_2017_toxicity = alldate_toxicity[alldate_toxicity['created_date'] == '2017-01-01']\n",
    "\n",
    "def check_frequency(data = alldate_toxicity['comment_text'], n = 20):\n",
    "    stop = stopwords.words('english')\n",
    "    data  = data.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    data = data.str.replace('[^\\w\\s]','')\n",
    "    data = data.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    freq = pd.Series(' '.join(data).split()).value_counts()[:n]\n",
    "    return freq\n",
    "\n",
    "top_10_toxicity_othertime = check_frequency(data = alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'], n = 10)\n",
    "top_10_toxicity_jan_2017 = check_frequency(data = jan_2017_toxicity['comment_text'], n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_toxicity_othertime = top_10_toxicity_othertime/alldate_toxicity[alldate_toxicity['created_date'] != '2017-01-01']['comment_text'].str.split().str.len().sum()\n",
    "percent_toxicity_jan_2017 = top_10_toxicity_jan_2017/jan_2017_toxicity['comment_text'].str.split().str.len().sum()\n",
    "top_toxicity = pd.concat([percent_toxicity_jan_2017, percent_toxicity_othertime], axis=1, sort=False)\n",
    "top_toxicity.columns = ['Jan_2017', 'Other_Time']\n",
    "top_toxicity['Difference'] = top_toxicity['Jan_2017'] - top_toxicity['Other_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan_2017</th>\n",
       "      <th>Other_Time</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>-0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>-0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>-0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>-0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>-0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupid</th>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>-0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Jan_2017  Other_Time  Difference\n",
       "trump   0.005175    0.004231    0.000943\n",
       "people  0.003828    0.004018   -0.000191\n",
       "like    0.003643    0.003650   -0.000007\n",
       "dont    0.002613    0.002662   -0.000049\n",
       "one     0.002587    0.002684   -0.000097\n",
       "would   0.002556    0.002828   -0.000271\n",
       "us      0.002512    0.001903    0.000609\n",
       "get     0.002296    0.002427   -0.000131\n",
       "stupid  0.001985    0.002072   -0.000087\n",
       "think   0.001680    0.001696   -0.000017"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_toxicity.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~moggirain/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=top_toxicity.index,\n",
    "    y=top_toxicity['Jan_2017'],\n",
    "    name='Jan_2017'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=top_toxicity.index,\n",
    "    y=top_toxicity['Other_Time'],\n",
    "    name='Other_Time'\n",
    ")\n",
    "\n",
    "data = [trace2, trace1]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "layout = go.Layout(yaxis=dict(tickformat=\".2%\"))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, title = 'Top Toxicity Comarision', filename='top_toxicity_comarision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Time are People More Toxic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['datetime64'] = pd.to_datetime(train['created_date']).values.astype('datetime64[h]')\n",
    "train['hour'] = train['datetime64'].dt.hour\n",
    "all_comments_by_hour = train['target'].groupby(train['hour']).sum().sort_index()/train['target'].groupby(train['hour']).sum().sum()\n",
    "toxic_comments_by_hour = train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sort_index()/train[train['target'] >= 0.5]['target'].groupby(train['hour']).sum().sum()\n",
    "comments_hour_check = pd.concat([all_comments_by_hour, toxic_comments_by_hour], axis=1, sort=False)\n",
    "comments_hour_check.columns = ['all_comments', 'toxic_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~moggirain/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Midnight', 'Morning', 'Noon', 'Evening', 'Midnight']\n",
    "tickvals = ['0', '6', '12', '18', comments_hour_check.index.max()]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=comments_hour_check.index,\n",
    "    y=comments_hour_check['all_comments'],\n",
    "    name = 'comment percent per H',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 1)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=comments_hour_check.index,\n",
    "    y=comments_hour_check['toxic_comments'],\n",
    "    name = 'toxic comment percent per H',\n",
    "    line = dict(\n",
    "        color = ('rgb(205, 12, 24)'),\n",
    "        width = 1,)\n",
    ")\n",
    "\n",
    "trace3 = go.Bar(\n",
    "    x=comments_hour_check.index,\n",
    "    y=comments_hour_check['toxic_comments']-comments_hour_check['all_comments'],\n",
    "    name = 'More Toxic Comment Ratio'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(yaxis=dict(tickformat=\".2%\"),\n",
    "                   title = 'Which Time are People More Toxic',\n",
    "                   xaxis=go.layout.XAxis(\n",
    "                       ticktext=labels, \n",
    "                       tickvals=tickvals\n",
    "                   ),\n",
    "                  )\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='Which Time are People More Toxic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe a simple bell-shaped normal distribution of the average word length with a mean of around 4.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:57.555217Z",
     "start_time": "2019-06-09T16:46:57.549112Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess the trian data and model a subset of the comments from train data\n",
    "def preprocess (text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:46:57.562541Z",
     "start_time": "2019-06-09T16:46:57.558959Z"
    }
   },
   "outputs": [],
   "source": [
    "# test for one comment \n",
    "# comment_sample = train['comment_text'][:1].values[0]\n",
    "# print(f'Original comment: {comment_sample}')\n",
    "# print(f'Tokenized comment: {preprocess(comment_sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:47:15.071745Z",
     "start_time": "2019-06-09T16:46:57.566176Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize the sampling data \n",
    "preprocessed = train['comment_text'].sample(200000).map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:47:15.088832Z",
     "start_time": "2019-06-09T16:47:15.074102Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the tokenization\n",
    "preprocessed.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:47:21.323136Z",
     "start_time": "2019-06-09T16:47:15.092817Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a dictionary\n",
    "dictionary = gensim.corpora.Dictionary(preprocessed)\n",
    "# filter extreme data \n",
    "dictionary.filter_extremes(no_below = 10, no_above = 0.5, keep_n = 75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T01:38:08.681054Z",
     "start_time": "2019-06-09T01:38:08.674997Z"
    }
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:47:26.964730Z",
     "start_time": "2019-06-09T16:47:21.325482Z"
    }
   },
   "outputs": [],
   "source": [
    "# measure the presence of words \n",
    "# output word idx and its frequency \n",
    "bow = [dictionary.doc2bow(doc) for doc in preprocessed]\n",
    "# tfidf\n",
    "tfidf = models.TfidfModel(bow)\n",
    "corpus_tfidf = tfidf[bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T01:47:45.824795Z",
     "start_time": "2019-06-09T01:47:45.140998Z"
    }
   },
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T18:54:50.418649Z",
     "start_time": "2019-06-09T18:52:22.969227Z"
    }
   },
   "outputs": [],
   "source": [
    "# build LDA model \n",
    "lda = gensim.models.LdaMulticore(corpus_tfidf, num_topics= 20,\n",
    "                                id2word = dictionary, passes = 2, workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:11:19.828006Z",
     "start_time": "2019-06-09T19:11:19.811529Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate the topics \n",
    "topics = lda.print_topics(num_words = 8)\n",
    "for i, topic in enumerate(topics[:10]):\n",
    "    print(f\"Train topic{i} {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:11:23.358717Z",
     "start_time": "2019-06-09T19:11:23.353288Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict the type fo topic for one document with the index = 10\n",
    "bd10 = bow[10]\n",
    "for i in range(len(bd10)):\n",
    "    print(f\"Word {bd10[i][0]} (\\'{dictionary[bd10[i][0]]}\\')  appears  {bd10[i][1]} time. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:11:28.248042Z",
     "start_time": "2019-06-09T19:11:28.230136Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, score in sorted(lda[bd10], key = lambda tup: -1*tup[1]):\n",
    "    print(f\"\\nScore: {score}\\t \\nTopic:{lda.print_topic(idx, 8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:12:40.495359Z",
     "start_time": "2019-06-09T19:11:31.427991Z"
    }
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda,bow,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:12:43.633797Z",
     "start_time": "2019-06-09T19:12:43.598483Z"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'LDAis_train.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:13:17.936391Z",
     "start_time": "2019-06-09T19:13:17.930214Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the most important topics per each comment \n",
    "def topic_sentences(ldamodel = lda, corpus = bow, texts = preprocessed):\n",
    "    \n",
    "    # initalization\n",
    "    topic_df = pd.DataFrame()\n",
    "    \n",
    "    # get main topic in each comment \n",
    "    # lda[corpus] ouput tuple (topic_num, proportion)\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key = lambda x: (x[1]), reverse = True)\n",
    "         # get the domain topic, %contribution and keywords for each document\n",
    "            # sorted by proportion\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: # = dominant topic\n",
    "                # display the topic as (words, proportion)\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                # join the keywords in a list\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                # build a dataframe\n",
    "                topic_df = topic_df.append(pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]), ignore_index = True)\n",
    "            else:\n",
    "                break\n",
    "    # concatnet topic and text \n",
    "    text = pd.Series(texts)\n",
    "    topic_df = pd.concat([topic_df, text],axis = 1)\n",
    "    return(topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:43:34.742082Z",
     "start_time": "2019-06-09T19:13:21.919972Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_keywords = topic_sentences(ldamodel = lda, corpus = bow, texts = preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:49:06.944620Z",
     "start_time": "2019-06-09T19:49:02.482715Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_keywords.to_csv(\"lda_model_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:49:10.269877Z",
     "start_time": "2019-06-09T19:49:10.162175Z"
    }
   },
   "outputs": [],
   "source": [
    "dominant_topic = topic_keywords.reset_index()\n",
    "dominant_topic.columns = ['Comment','Dominant_topic','Topic_percent_contribution','Keywords','Text']\n",
    "dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:49:34.288935Z",
     "start_time": "2019-06-09T19:49:17.196776Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize comments \n",
    "preprocessed_comments = test['comment_text'].map(preprocess)\n",
    "# create dictionary \n",
    "dictionary = gensim.corpora.Dictionary(preprocessed_comments)\n",
    "# filter the dictionary \n",
    "dictionary.filter_extremes(no_below = 10, no_above = 0.5, keep_n = 75000)\n",
    "# bag of words\n",
    "bow_test = [dictionary.doc2bow(doc) for doc in preprocessed_comments]\n",
    "# tfidf ouput the tfidf scores tf*idf\n",
    "tfidf = models.TfidfModel(bow_test)\n",
    "# dictionary for each bag tfidf\n",
    "corpus_tfidf = tfidf[bow_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:50:42.423151Z",
     "start_time": "2019-06-09T19:49:38.411439Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics= 20, id2word= dictionary, passes = 2, workers= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:50:47.329251Z",
     "start_time": "2019-06-09T19:50:47.306764Z"
    }
   },
   "outputs": [],
   "source": [
    "topics = lda_model.print_topics(num_words = 5)\n",
    "for i, topic in enumerate(topics[:10]):\n",
    "    \n",
    "    print(f\"Test topic {i}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:51:32.978969Z",
     "start_time": "2019-06-09T19:50:50.592279Z"
    }
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda_model, bow_test, dictionary)\n",
    "pyLDAvis.save_html(vis,\"LDAVis_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment (negativity)\n",
    "#### The blue distribution is label 0 (non-toxic) and the red[](http://) distribution is label 1 (toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >0.5 is toxic and <0.5 is non-toxic\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "polarity_0 = train.loc[train.target < 0.5][col].apply(lambda x:SIA.polarity_scores(x))\n",
    "polarity_1 = train.loc[train.target > 0.5][col].apply(lambda x:SIA.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sentiment\n",
    "sns.distplot([polarity['neg'] for polarity in polarity_0], color = 'blue')\n",
    "sns.distplot([polarity['neg'] for polarity in polarity_1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clearly, the blue distribution has a higher mean than the red distribution. Both distributions shared sismilar std. Although both distributions are skewed leftwards, the red distribution has a stronger leftward skew.\n",
    "- The trend indicated that the toxic comments generally tend to be more negative on average. This is probably because most comments considered \"toxic\" generally spread negative emotions like hate, anger or insult against certain people, beliefs or opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment (positivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([polarity['pos'] for polarity in polarity_0], color='blue')\n",
    "sns.distplot([polarity['pos'] for polarity in polarity_1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both two distributions shared similar characteristics : bimodality, shape, skew, mean etc.It indicated there is no significant difference between positivity in toxic and non-toxic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment (neutrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([polarity['neu'] for polarity in polarity_0], color='blue')\n",
    "sns.distplot([polarity['neu'] for polarity in polarity_1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment (compoundness / complexity of comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([polarity['compound'] for polarity in polarity_0], color='darkorange')\n",
    "sns.distplot([polarity['compound'] for polarity in polarity_1], color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation***\n",
    "- Both distributions have a somewhat similar shape : evenly spread out with little skew in one direction and a small insignificant peak in the center (at around 0). The skewness is different. \n",
    "- This shows that toxic comments are generally less gramatically complex than non-toxic comments. It is probably because toxic comments are generally more blunt and short. \n",
    "- On the other hand, non-toxic comments generally try to share a perspective or make a point, and thus, they tend to be more gramatically complex or compounded on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules for model preparation using Deeplearning**\n",
    "\n",
    "- Don't use standard preprocessing steps like stemming or stopword removal when you have pre-trained embeddings\n",
    "- Get your vocabulary as close to the embeddings as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EMBED_SIZE` - embedding size - the size of word vector - should match the embedding source (GloVe);\n",
    "<br>\n",
    "`MAX_FEATURES` - Maximum number of features - the number of unique words to use or number of rows in the embedding vector;\n",
    "<br>\n",
    "`MAXLEN` - The maximum length of comments text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:59:31.798938Z",
     "start_time": "2019-06-09T19:59:31.794011Z"
    }
   },
   "outputs": [],
   "source": [
    " # size of word vector; this should be set to 300 to match the embedding source\n",
    "EMBED_SIZE = 300\n",
    "# how many unique words to use (i.e num rows in embedding vector)\n",
    "MAX_FEATURES = 100000 \n",
    "# max length of comments text\n",
    "MAXLEN = 220 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T19:59:35.708332Z",
     "start_time": "2019-06-09T19:59:35.697644Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(texts):\n",
    "    \"\"\"\n",
    "    credits to: https://www.kaggle.com/gpreda/jigsaw-eda#Prepare-the-model\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: list of list of words\n",
    "    output: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in tqdm_notebook(sentences):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T20:02:30.006147Z",
     "start_time": "2019-06-09T19:59:39.387199Z"
    }
   },
   "outputs": [],
   "source": [
    "# concatnate train and test and build an unique vocabulary with both datasets\n",
    "# populate the vocabulary \n",
    "df = pd.concat([train,test], sort = False)\n",
    "vocabulary = build_vocabulary(df['comment_text'])\n",
    "print({k: vocabulary[k] for k in list(vocabulary)[:10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index and Matrix Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T20:02:54.370422Z",
     "start_time": "2019-06-09T20:02:54.334295Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_embeddings(file):\n",
    "    \"\"\"\n",
    "    credits to: https://www.kaggle.com/takuok/glove840b300dtxt/downloads/glove.840B.300d.txt/1\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: embeddings file\n",
    "    output: embedding index\n",
    "    \"\"\"\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "    return embeddings_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T20:06:30.033500Z",
     "start_time": "2019-06-09T20:02:54.438035Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert it to glove path\n",
    "GLOVE_PATH = './'\n",
    "print(\"Extracting GloVe embedding started\")\n",
    "embed_glove = load_embeddings(os.path.join(GLOVE_PATH,'glove.840B.300d.txt'))\n",
    "print(\"Embedding completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T21:00:09.391731Z",
     "start_time": "2019-06-09T20:02:55.729Z"
    }
   },
   "outputs": [],
   "source": [
    "len(embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T21:00:19.295576Z",
     "start_time": "2019-06-09T21:00:19.261420Z"
    }
   },
   "outputs": [],
   "source": [
    "def embedding_matrix(word_index, embeddings_index):\n",
    "    '''\n",
    "    credits to:https://www.kaggle.com/takuok/glove840b300dtxt/downloads/glove.840B.300d.txt/1\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: word index, embedding index\n",
    "    output: embedding matrix\n",
    "    '''\n",
    "    # enbedding matrix-stack all the index \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    # calculate embedding mean and std\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    # set teh size \n",
    "    EMBED_SIZE = all_embs.shape[1]\n",
    "    # number of words\n",
    "    nb_words = min(MAX_FEATURES, len(word_index))\n",
    "    # initiate embedding matrix \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBED_SIZE))\n",
    "    # iterate to get word embedding for each word\n",
    "    for word, i in tqdm_notebook(word_index.items()):\n",
    "        if i >= MAX_FEATURES:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Coverage\n",
    "- Check coverage of  embeddings for the vocabulary created from the train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T22:52:13.603155Z",
     "start_time": "2019-06-09T22:52:13.548061Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embeddings_index):\n",
    "    \"\"\"\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: vocabulary, embedding index\n",
    "    output: list of unknown words; also prints the vocabulary coverage of embeddings and the % of comments text covered by the embeddings\n",
    "    \n",
    "    \"\"\"\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in tqdm_notebook(vocab.keys()):\n",
    "        try:\n",
    "            # build dictionary for known_words\n",
    "            known_words[word] = enbeddings_index[word]\n",
    "            # nb_known_words \n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab [word]\n",
    "            pass\n",
    "    print('Found embeddings for {:.3%} of vocabulary'.format(len(known_words)/len(vocab)))\n",
    "    print('Found embeddings for {:.3%} of all text'.format(nb_known_words/(nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T00:32:42.970049Z",
     "start_time": "2019-06-10T00:32:26.024773Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Verify the intial vocabulary coverage\")\n",
    "oov_glove = check_coverage(vocabulary, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T01:24:09.795905Z",
     "start_time": "2019-06-10T00:43:50.849Z"
    }
   },
   "outputs": [],
   "source": [
    "oov_glove[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lower(embedding, vocab):\n",
    "    '''\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: vocabulary, embedding matrix\n",
    "    output: modify the embeddings to include the lower case from vocabulary\n",
    "    '''\n",
    "    count = 0\n",
    "    for word in tqdm_notebook(vocab):\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(lambda x: x.lower())\n",
    "test['comment_text'] = test['comment_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check coverage for vocabulary with lower case\")\n",
    "# check oov_glove coverage \n",
    "oov_glove = check_coverage(vocabulary, embed_glove)\n",
    "add_lower(embed_glove, vocabulary) # operates on the same vocabulary\n",
    "oov_glove = check_coverage(vocabulary, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_glove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Contradictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "len(contraction_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known_contractions(embed):\n",
    "    '''\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: embedding matrix\n",
    "    output: known contractions (from embeddings)\n",
    "    '''\n",
    "    known = []\n",
    "    for contract in tqdm_notebook(contraction_mapping):\n",
    "        if contract in embed:\n",
    "            known.append(contract)\n",
    "    return known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Known contractions in GloVe embeddings:\")\n",
    "print(known_contractions(embed_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_contractions(text, mapping):\n",
    "    '''\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: current text, contraction mappings\n",
    "    output: modify the comments to use the base form from contraction mapping\n",
    "    '''\n",
    "    specials = [\"\", \"\", \"\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "test['comment_text'] = test['comment_text'].apply(lambda x: clean_contractions(x, contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train ,test], sort=False)\n",
    "vocab = build_vocabulary(df['comment_text'])\n",
    "print(\"Check embeddings after applying contraction mapping\")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_glove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_mapping = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"' + '\\&'\n",
    "punct_mapping += '^` < '\n",
    "\n",
    "def unknown_punct(embed, punct):\n",
    "    '''\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: current text, contraction mappings\n",
    "    output: unknown punctuation\n",
    "    '''\n",
    "    unknown = ''\n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Find unknown punctuation:\")\n",
    "print(unknown_punct(embed_glove, punct_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = {\"\": \"'\", \"\": \"'\", \"\": \"\", \"\": \"e\", \"\": \"-\", \"\": \"-\", \"\": \"'\", \"_\": \"-\", \"`\": \"'\", '': '\"', '': '\"', '': '\"', \"\": \"e\", '': 'infinity', '': 'theta', '': '/', '': 'alpha', '': '.', '': 'a', '': '-', '': 'beta', '': '', '': '3', '': 'pi', '': ' '}\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''\n",
    "    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n",
    "    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n",
    "    input: current text, punctuations, punctuation mapping\n",
    "    output: cleaned text\n",
    "    '''\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ') \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))\n",
    "test['comment_text'] = test['comment_text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.concat([train ,test], sort=False)\n",
    "vocab = build_vocabulary(df['comment_text'])\n",
    "print(\"Check coverage after punctuation replacement\")\n",
    "oov_glove = check_coverage(vocab, embed_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(list(train))\n",
    "train = tokenizer.texts_to_sequences(train)\n",
    "test = tokenizer.texts_to_sequences(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
